[gemini]
gemini_model=gemini-1.5-pro
# gemini_model=gemini-1.5-flash
; temperature: Controls the "randomness" or creativity of the generated text.
;   Higher values (e.g., 1.0): More creative, unexpected text, potentially including made-up words or nonsensical phrases. Good for brainstorming or exploring diverse ideas.
;   Lower values (e.g., 0.2): More predictable, focused text that sticks closely to common phrases and patterns. Good for tasks requiring factual accuracy or specific formatting.
temperature=0.1
;top_p (nucleus sampling): Considers only the most likely tokens whose cumulative probability exceeds the top_p value.
;   Higher values (e.g., 0.95): Includes a wider range of possible words, leading to more diverse outputs.
;   Lower values (e.g., 0.5): Focuses on the most probable words, resulting in more predictable and potentially repetitive text.
top_p=0.95
;top_k: Considers only the top k most likely tokens at each generation step. Similar to top_p but uses a fixed number of tokens instead of a probability threshold. Often used in conjunction with t>
top_k=40
;max_output_tokens: Limits the length of the generated response. 8192 tokens is a relatively long output, allowing for extensive text generation. This prevents the model from running indefinitely >
max_output_tokens=8192

[system]
google_folder_id=0AKnIrjV7IbgFUk9PVA
big_query_bucket_id=slackbot-gcp-v1
prompt_file=configure/prompt.ini
audio_file_formats=audio/mp4,audio/mpeg,audio/vnd.wave,audio/wav,audio/mp3,audio/aiff,audio/aac,audio/ogg,audio/flac